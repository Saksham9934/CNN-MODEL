{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bafd56f-14c4-4984-8d83-b45909961f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\AI-09\\anaconda.4\\envs\\intern\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e7b5a85-7208-487e-a7de-9d0a665b4649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     image_name  patient_id     sex  age_approx anatom_site_general_challenge  \\\n",
      "0  ISIC_2637011  IP_7279968    male        45.0                     head/neck   \n",
      "1  ISIC_0015719  IP_3075186  female        45.0               upper extremity   \n",
      "2  ISIC_0052212  IP_2842074  female        50.0               lower extremity   \n",
      "3  ISIC_0068279  IP_6890425  female        45.0                     head/neck   \n",
      "4  ISIC_0074268  IP_8723313  female        55.0               upper extremity   \n",
      "\n",
      "  diagnosis benign_malignant  target  \n",
      "0   unknown           benign       0  \n",
      "1   unknown           benign       0  \n",
      "2     nevus           benign       0  \n",
      "3   unknown           benign       0  \n",
      "4   unknown           benign       0  \n"
     ]
    }
   ],
   "source": [
    "data_dir = 'C:/Users/AI-09/Desktop/Project/ISIC-images'\n",
    "label_file = 'C:/Users/AI-09/Desktop/Project/ISIC_2020_Training_GroundTruth.csv'\n",
    "output_dir = 'C:/Users/AI-09/Desktop/Project/output'\n",
    "\n",
    "labels_df = pd.read_csv(label_file)\n",
    "print(labels_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88bf4ab1-c35a-468c-8c0b-b6ba88a2a683",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_encoder = LabelEncoder()\n",
    "labels_df['target'] = label_encoder.fit_transform(labels_df['target'])\n",
    "labels_df['target'] = labels_df['target'].astype(str)  # Convert labels to string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa5b3475-0137-4da4-aa67-0fd0b7f9a2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(labels_df, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fff5e9c-2346-4272-8349-5728d0632b3b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 27) (2955640442.py, line 27)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 27\u001b[1;36m\u001b[0m\n\u001b[1;33m    class_mode='categorical)\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 27)\n"
     ]
    }
   ],
   "source": [
    "image_size = (128, 128)\n",
    "batch_size = 32\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255,\n",
    "                             rotation_range=20,\n",
    "                             width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,\n",
    "                             shear_range=0.2,\n",
    "                             zoom_range=0.2,\n",
    "                             horizontal_flip=True,\n",
    "                             fill_mode='nearest')\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(train_df,\n",
    "                                              directory=data_dir,\n",
    "                                              x_col='image_name',\n",
    "                                              y_col='target',\n",
    "                                              target_size=image_size,\n",
    "                                              batch_size=batch_size,\n",
    "                                              class_mode='categorical')\n",
    "\n",
    "val_generator = datagen.flow_from_dataframe(val_df,\n",
    "                                            directory=data_dir,\n",
    "                                            x_col='image_name',\n",
    "                                            y_col='target',\n",
    "                                            target_size=image_size,\n",
    "                                            batch_size=batch_size,\n",
    "                                            class_mode='categorical)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b79a5d5e-da33-43bb-8953-f9961a1bb524",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(labels_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(data_dir)[:\u001b[38;5;241m5\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'labels_df' is not defined"
     ]
    }
   ],
   "source": [
    "print(labels_df['image_name'].head())\n",
    "print(os.listdir(data_dir)[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9e72837-c6af-4bac-819d-9d61a0c65c86",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Example to add .jpg extension if missing\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m labels_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m labels_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: x \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'labels_df' is not defined"
     ]
    }
   ],
   "source": [
    "# Example to add .jpg extension if missing\n",
    "labels_df['image_name'] = labels_df['image_name'].apply(lambda x: x if x.endswith('.jpg') else x + '.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f037fefb-2362-416f-beb8-2874bb78496a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir ='C:/Users/AI-09/Desktop/Project/ISIC-images'\n",
    "if not os.path.exists(data_dir):\n",
    "    print(f\"Directory {data_dir} does not exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195e07cd-2f69-414f-9626-e611355bf063",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_files = [f for f in labels_df['image_name'] if not os.path.exists(f)]\n",
    "if missing_files:\n",
    "    print(f\"Missing files: {missing_files[:5]}\")  # Print first 5 missing files as a sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f9b700-86a3-44cc-bb2d-7e8719af5774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Ensure the file paths are correct\n",
    "labels_df['image_name'] = labels_df['image_name'].apply(lambda x: os.path.join(data_dir, x))\n",
    "\n",
    "# Proceed with data augmentation\n",
    "image_size = (128, 128)\n",
    "batch_size = 32\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255,\n",
    "                             rotation_range=20,\n",
    "                             width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,\n",
    "                             shear_range=0.2,\n",
    "                             zoom_range=0.2,\n",
    "                             horizontal_flip=True,\n",
    "                             fill_mode='nearest')\n",
    "\n",
    "train_df, val_df = train_test_split(labels_df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(train_df,\n",
    "                                              x_col='image_name',\n",
    "                                              y_col='target',\n",
    "                                              target_size=image_size,\n",
    "                                              batch_size=batch_size,\n",
    "                                              class_mode='categorical')\n",
    "\n",
    "val_generator = datagen.flow_from_dataframe(val_df,\n",
    "                                            x_col='image_name',\n",
    "                                            y_col='target',\n",
    "                                            target_size=image_size,\n",
    "                                            batch_size=batch_size,\n",
    "                                            class_mode='categorical')\n",
    "\n",
    "# Verify the generator results\n",
    "print(f\"Found {train_generator.samples} validated image filenames belonging to {train_generator.num_classes} classes.\")\n",
    "print(f\"Found {val_generator.samples} validated image filenames belonging to {val_generator.num_classes} classes.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c33705d-c1c1-4151-aeb6-1a7ad80a3452",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Ensure the file paths are correct\n",
    "labels_df['image_name'] = labels_df['image_name'].apply(lambda x: os.path.join(data_dir, x))\n",
    "\n",
    "# Proceed with data augmentation\n",
    "image_size = (128, 128)\n",
    "batch_size = 32\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255,\n",
    "                             rotation_range=20,\n",
    "                             width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,\n",
    "                             shear_range=0.2,\n",
    "                             zoom_range=0.2,\n",
    "                             horizontal_flip=True,\n",
    "                             fill_mode='nearest')\n",
    "\n",
    "train_df, val_df = train_test_split(labels_df, test_size=0.2, random_state=42)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(train_df,\n",
    "                                              x_col='image_name',\n",
    "                                              y_col='target',\n",
    "                                              target_size=image_size,\n",
    "                                              batch_size=batch_size,\n",
    "                                              class_mode='categorical')\n",
    "\n",
    "val_generator = datagen.flow_from_dataframe(val_df,\n",
    "                                            x_col='image_name',\n",
    "                                            y_col='target',\n",
    "                                            target_size=image_size,\n",
    "                                            batch_size=batch_size,\n",
    "                                            class_mode='categorical')\n",
    "\n",
    "# Verify the generator results\n",
    "print(f\"Found {train_generator.samples} validated image filenames belonging to {len(train_generator.class_indices)} classes.\")\n",
    "print(f\"Found {val_generator.samples} validated image filenames belonging to {len(val_generator.class_indices)} classes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32291e1-19b4-45ad-9117-61736deb6768",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(labels_df.head())\n",
    "print(\"Data Directory:\", data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b99828c-fc39-4aca-b290-e56a243846c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(train_generator.class_indices), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "epochs = 2\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=val_generator)\n",
    "\n",
    "# Plot the training history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_loss, val_acc = model.evaluate(val_generator)\n",
    "print(f\"Validation accuracy: {val_acc:.4f}\")\n",
    "\n",
    "# Save the model\n",
    "model.save(os.path.join(output_dir, 'skin_cancer_cnn_model.h5'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daf0512-d254-49fc-9fa2-bee7db02da43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(train_generator.class_indices), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "epochs = 25\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=val_generator)\n",
    "\n",
    "# Plot the training history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_loss, val_acc = model.evaluate(val_generator)\n",
    "print(f\"Validation accuracy: {val_acc:.4f}\")\n",
    "\n",
    "# Save the model\n",
    "model.save(os.path.join(output_dir, 'skin_cancer_cnn_model.h5'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64d6664-8584-4370-81e9-3a62b2a24c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(train_generator.class_indices), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "epochs = 2\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=val_generator)\n",
    "\n",
    "# Plot the training history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_loss, val_acc = model.evaluate(val_generator)\n",
    "print(f\"Validation accuracy: {val_acc:.4f}\")\n",
    "\n",
    "# Save the model\n",
    "model.save(os.path.join(output_dir, 'skin_cancer_cnn_model.h5'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fbbbed-b95c-48c0-b2e3-8545c35875d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "import os\n",
    "# Define a simple CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Assuming you have your training data in variables X_train and y_train\n",
    "# model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Now you can save the model\n",
    "output_dir = 'C:/Users/AI-09/Desktop/Project/output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "model.save(os.path.join(output_dir, 'skin_cancer_cnn_model.keras'))\n",
    "print(\"Model saved successfully in Keras native format.\")\n",
    "\n",
    "model.save(os.path.join(output_dir, 'skin_cancer_cnn_model'))\n",
    "print(\"Model saved successfully in TensorFlow SavedModel format.\")\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Define a simple CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Assuming you have your training data in variables X_train and y_train\n",
    "# model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Now you can save the model\n",
    "output_dir = 'C:/Users/AI-09/Desktop/Project/output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "model.save(os.path.join(output_dir, 'skin_cancer_cnn_model.keras'))\n",
    "print(\"Model saved successfully in Keras native format.\")\n",
    "\n",
    "model.save(os.path.join(output_dir, 'skin_cancer_cnn_model'))\n",
    "print(\"Model saved successfully in TensorFlow SavedModel format.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e2d750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "image_path = 'C:/Users/AI-09/Desktop/Project/ISIC-images/ISIC_0015719.jpg'\n",
    "\n",
    "# Check if the file exists and is readable\n",
    "if os.path.exists(image_path) and os.access(image_path, os.R_OK):\n",
    "    print(\"File exists and is readable\")\n",
    "else:\n",
    "    print(\"File does not exist or is not readable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d217430-3cf4-407b-b7ee-9fb4d34fcecf",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 126] The specified module could not be found. Error loading \"C:\\Users\\AI-09\\anaconda.4\\envs\\intern\\Lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m YOLO\n",
      "File \u001b[1;32m~\\anaconda.4\\envs\\intern\\Lib\\site-packages\\ultralytics\\__init__.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Set ENV Variables (place before imports)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOMP_NUM_THREADS\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# reduce CPU utilization during training\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexplorer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexplorer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Explorer\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NAS, RTDETR, SAM, YOLO, FastSAM, YOLOWorld\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ASSETS, SETTINGS\n",
      "File \u001b[1;32m~\\anaconda.4\\envs\\intern\\Lib\\site-packages\\ultralytics\\data\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Ultralytics YOLO 🚀, AGPL-3.0 license\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseDataset\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuild\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_dataloader, build_grounding, build_yolo_dataset, load_inference_source\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      6\u001b[0m     ClassificationDataset,\n\u001b[0;32m      7\u001b[0m     GroundingDataset,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     YOLOMultiModalDataset,\n\u001b[0;32m     12\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda.4\\envs\\intern\\Lib\\site-packages\\ultralytics\\data\\base.py:15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpsutil\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FORMATS_HELP_MSG, HELP_URL, IMG_FORMATS\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DEFAULT_CFG, LOCAL_RANK, LOGGER, NUM_THREADS, TQDM\n",
      "File \u001b[1;32m~\\anaconda.4\\envs\\intern\\Lib\\site-packages\\torch\\__init__.py:148\u001b[0m\n\u001b[0;32m    146\u001b[0m                 err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(ctypes\u001b[38;5;241m.\u001b[39mget_last_error())\n\u001b[0;32m    147\u001b[0m                 err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 148\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    150\u001b[0m     kernel32\u001b[38;5;241m.\u001b[39mSetErrorMode(prev_error_mode)\n\u001b[0;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_preload_cuda_deps\u001b[39m(lib_folder, lib_name):\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 126] The specified module could not be found. Error loading \"C:\\Users\\AI-09\\anaconda.4\\envs\\intern\\Lib\\site-packages\\torch\\lib\\fbgemm.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Initialize the model with YOLOv8\n",
    "model = YOLO('yolov8n-cls.pt')  # Load a pre-trained YOLOv8 model\n",
    "\n",
    "# Train the model\n",
    "model.train(\n",
    "    data='data_dict.yaml',  # Path to dataset YAML configuration file\n",
    "    epochs=2,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    name='skin_cancer_cnn_model'\n",
    ")\n",
    "# Load the best weights\n",
    "model = YOLO('skin_cancer_cnn_model.pt')\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true_classes, y_pred_classes, average='weighted')\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-score: {f1_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e645dd1-7e8f-4d05-8dcf-24418e0408a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import os\n",
    "\n",
    "# Load the saved model\n",
    "model = tf.keras.models.load_model('C:/Users/AI-09/Desktop/Project/output/skin_cancer_cnn_model')\n",
    "# Load your test dataset\n",
    "X_test = np.load('C:/Users\\AI-09\\Desktop\\Project\\Label\\ISIC_0015719.txt')\n",
    "y_test = np.load('/path/to/y_test.npy')\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true_classes, y_pred_classes, average='weighted')\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-score: {f1_score}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
